/**
 * Test Runner Script
 * Runs all tests and logs bugs to a file
 */
import { exec } from 'child_process';
import { promisify } from 'util';
import * as fs from 'fs';
import * as path from 'path';

const execAsync = promisify(exec);

interface TestResult {
  testCase: string;
  status: 'PASS' | 'FAIL' | 'SKIP';
  error?: string;
  duration?: number;
}

interface BugReport {
  testCaseId: string;
  testCaseName: string;
  priority: string;
  status: string;
  error: string;
  expectedResult: string;
  actualResult: string;
  steps: string[];
  timestamp: string;
}

async function runTests(): Promise<void> {
  console.log('ðŸ§ª Running FitTrack Pro Test Suite...\n');

  try {
    // Run tests and capture output
    const { stdout, stderr } = await execAsync('npm run test:run 2>&1', {
      cwd: process.cwd(),
      maxBuffer: 10 * 1024 * 1024, // 10MB buffer
    });

    // Parse test results
    const bugs: BugReport[] = [];
    const testResults: TestResult[] = [];

    // Extract failed tests from output
    const failPattern = /FAIL\s+(.+?)\s+(.+?)\n/g;
    const errorPattern = /Error:\s+(.+?)\n/g;

    let match;
    while ((match = failPattern.exec(stdout)) !== null) {
      const testName = match[1];
      const testPath = match[2];
      
      // Extract error details
      const errorMatch = stdout.substring(stdout.indexOf(match[0])).match(/Error:\s+(.+?)(?=\n\n|\n\s+at)/s);
      const error = errorMatch ? errorMatch[1].trim() : 'Test failed';

      bugs.push({
        testCaseId: extractTestCaseId(testName),
        testCaseName: testName,
        priority: extractPriority(testName),
        status: 'FAIL',
        error: error,
        expectedResult: 'Test should pass',
        actualResult: error,
        steps: extractSteps(testName),
        timestamp: new Date().toISOString(),
      });
    }

    // Write bug report
    const bugReportPath = path.join(process.cwd(), 'BUG_REPORT.md');
    writeBugReport(bugs, bugReportPath, stdout);

    console.log(`\nâœ… Test execution completed!`);
    console.log(`ðŸ“Š Found ${bugs.length} failing tests`);
    console.log(`ðŸ“ Bug report written to: ${bugReportPath}\n`);

  } catch (error: any) {
    console.error('âŒ Error running tests:', error.message);
    
    // Still write bug report with error
    const bugs: BugReport[] = [{
      testCaseId: 'TEST-RUN-ERROR',
      testCaseName: 'Test Execution Error',
      priority: 'P0',
      status: 'ERROR',
      error: error.message || 'Unknown error',
      expectedResult: 'Tests should run successfully',
      actualResult: error.message || 'Test execution failed',
      steps: ['Run npm run test:run'],
      timestamp: new Date().toISOString(),
    }];

    writeBugReport(bugs, path.join(process.cwd(), 'BUG_REPORT.md'), error.stdout || error.message);
  }
}

function extractTestCaseId(testName: string): string {
  // Try to extract TC-XXX-XXX pattern
  const match = testName.match(/TC-[A-Z]+-\d+/);
  return match ? match[0] : 'UNKNOWN';
}

function extractPriority(testName: string): string {
  if (testName.includes('P0') || testName.includes('Critical')) return 'P0';
  if (testName.includes('P1') || testName.includes('High')) return 'P1';
  if (testName.includes('P2') || testName.includes('Medium')) return 'P2';
  return 'P3';
}

function extractSteps(testName: string): string[] {
  // This would ideally parse from test scenarios, but for now return generic
  return [
    'Execute test case',
    'Verify expected behavior',
    'Check for errors',
  ];
}

function writeBugReport(bugs: BugReport[], filePath: string, fullOutput: string): void {
  const report = `# Bug Report - FitTrack Pro
**Generated:** ${new Date().toISOString()}
**Test Run:** Automated Test Execution

## Summary

- **Total Bugs Found:** ${bugs.length}
- **Critical (P0):** ${bugs.filter(b => b.priority === 'P0').length}
- **High (P1):** ${bugs.filter(b => b.priority === 'P1').length}
- **Medium (P2):** ${bugs.filter(b => b.priority === 'P2').length}

---

## Bugs

${bugs.length === 0 
  ? 'âœ… No bugs found! All tests passed.' 
  : bugs.map((bug, index) => `
### Bug #${index + 1}: ${bug.testCaseId} - ${bug.testCaseName}

**Priority:** ${bug.priority}  
**Status:** ${bug.status}  
**Timestamp:** ${bug.timestamp}

**Test Case:** ${bug.testCaseName}

**Error:**
\`\`\`
${bug.error}
\`\`\`

**Expected Result:**
${bug.expectedResult}

**Actual Result:**
${bug.actualResult}

**Steps to Reproduce:**
${bug.steps.map((step, i) => `${i + 1}. ${step}`).join('\n')}

---
`).join('\n')}

## Full Test Output

\`\`\`
${fullOutput.substring(0, 5000)}${fullOutput.length > 5000 ? '\n... (truncated)' : ''}
\`\`\`

---

*This report was automatically generated by the test runner.*
`;

  fs.writeFileSync(filePath, report, 'utf-8');
}

// Run if executed directly
if (require.main === module) {
  runTests().catch(console.error);
}

export { runTests };

